[
    "----------------------------------------------------------------------------------------------------",
    "This project involves using model-based reinforcement learning to solve the 15-puzzle problem, ",
    "a sliding puzzle where the goal is to arrange numbered tiles in the correct order. The approach ",
    "relies on a Q-Table, a tabular data structure that stores values representing the expected utility of ",
    "taking specific actions in each possible state. The Q-Table helps the learning agent make decisions ",
    "by providing a way to evaluate which actions lead to more favorable outcomes over time.",
    "",
    "In this implementation, key parameters like learning rate and discount factor control how the ",
    "agent updates its understanding of the environment. The learning rate (learningRate in ",
    "config.json) determines how much new information overrides old knowledge, while the ",
    "discount factor (discount) influences how future rewards are valued relative to immediate ones.",
    "The configuration allows for the generation of a specified number of training examples (or ",
    "'lessons') to teach the model through repeated trials. For each lesson, various parameters such as ",
    "goals, start positions, and locked elements are defined, guiding the agent’s training process.",
    "The settings in config.json define these learning conditions, providing a structured approach to ",
    "gradually mastering the puzzle.",
    "----------------------------------------------------------------------------------------------------",
    "",
    "about puzzle - https://en.wikipedia.org/wiki/15_puzzle",
    "project source code - https://github.com/zc42/ml-puzzle-15-v1",
    "java port - https://github.com/zc42/game_15_java/blob/main/README.md",
    "python port for kaggle - https://www.kaggle.com/code/zilvinasc/reinforced-learning-qtable-puzzle-15",
    "development history - https://github.com/zc42/stuff",
    "----------------------------------------------------------------------------------------------------",
    "",
    "",
    "CONFIGURATION HELP",
    "",
    "",
    "Configuration is editable.",
    "----------------------------------------------------------------------------------------------------",
    "usePretrainedDataWhileTesting - boolean, true or false.",
    "When set to false, the q-table data learned in this session will be used.",
    "If the value is changed to true, the puzzle will attempt to solve itself, while using pretrained data.",
    "----------------------------------------------------------------------------------------------------",
    "basicTrainerConfig:",
    "",
    "learningRate - number, the learning rate determines how much new information overrides old knowledge.",
    "discount - number, discount factor influences how future rewards are valued relative to immediate ones.",
    "trainingBatchCount - number, the number of training cycles that will be executed in each batch.",
    "lessonsToGenerate - number, default number of episodes for training each lesson,",
    "used if a specific lesson does not have its ownlessonsToGenerate value set.",
    "----------------------------------------------------------------------------------------------------",
    "lessons:",
    "",
    "lesson - number, the number of the lesson. The order in withc leesons will be applied.",
    "goals - number array, the target positions for this lesson.",
    "startPositions - number array, starting positions for the empty tile.",
    "lockedElements - number array, tiles that are fixed and cannot be moved, usually representing the goals from previous lessons.",
    "All number arrays, valid numbers are from 1 to 15, movable tile nubers in a puzzle.",
    "",
    "lessonsToGenerate - number, the number of episodes that will be generated for this particular lesson in each training cycle.",
    "----------------------------------------------------------------------------------------------------",
    "----------------------------------------------------------------------------------------------------",
    "",
    "Some theory",
    "----------------------------------------------------------------------------------------------------",
    "QTable",
    "",
    "QTable refers to a 'Q-Table', which is used in Q-Learning, a type of reinforcement learning algorithm.",
    "A Q-Table is a table where:",
    "Rows represent states of the environment.",
    "Columns represent actions that an agent can take.",
    "Cells contain Q-values, which estimate the expected reward of taking a specific action in a specific state.",
    "The Q-value is updated over time using the Q-Learning formula:",
    "",
    "Q(s, a) ← Q(s, a) + α * [r + γ * max(Q(s', a')) - Q(s, a)]",
    "",
    "Where:",
    "s = current state",
    "a = action taken",
    "r = reward received",
    "s' = next state after taking action a",
    "α = learning rate (0 < α ≤ 1)",
    "γ = discount factor (0 ≤ γ < 1)",
    "The Q-Table helps an agent learn which actions to take in each state to maximize its cumulative reward over time.",
    "By iteratively updating the Q-values based on experiences, the agent learns an optimal policy for decision-making.",
    "----------------------------------------------------------------------------------------------------",
    "",
    "Model-based reinforcement learning",
    "",
    "Model-based reinforcement learning is an approach where the agent learns a model of the ",
    "environment, including how actions affect states and the rewards they yield. The agent uses ",
    "this model to simulate future outcomes and plan its actions, making decisions based on predictions ",
    "rather than just past experiences. This can improve learning efficiency since the agent can learn ", 
    "from simulated interactions, but it depends on the accuracy of the learned model."    
]